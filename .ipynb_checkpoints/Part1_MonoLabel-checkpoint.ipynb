{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s-ywOfU3pDyJ"
   },
   "source": [
    "# Predict tags for job offers with linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0TpdAN6ZpDyK"
   },
   "source": [
    "In this notebook we are going to predict tags for job offers.\n",
    "\n",
    "tags: ['company' 'jobdescription' 'joblocation_address' 'jobtitle' 'skills']\n",
    "\n",
    "### Libraries\n",
    "\n",
    "- Numpy - a package for scientific computing.\n",
    "- Pandas - a library providing high-performance, easy-to-use data structures and data analysis tools for the Python\n",
    "- Scikit-learn - a tool for data mining and data analysis.\n",
    "- NLTK - a platform to work with natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JA3cfHoZpDyL"
   },
   "source": [
    "### Train and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbyuwJ4RpDyM"
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "MN_bKYFop6Al",
    "outputId": "5d929550-8af5-4b72-ca13-945b65a064bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development engineer – time metrology</td>\n",
       "      <td>skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whose mandate provide basis coherent system m...</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bipm base sèvres outskirts  staff 70</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>laboratory equip characterization gnss time t...</td>\n",
       "      <td>skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>principal duty responsibility reporting direct...</td>\n",
       "      <td>skills</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence      Tag\n",
       "0              development engineer – time metrology   skills\n",
       "1   whose mandate provide basis coherent system m...  company\n",
       "2               bipm base sèvres outskirts  staff 70  company\n",
       "3   laboratory equip characterization gnss time t...   skills\n",
       "4  principal duty responsibility reporting direct...   skills"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_dropna.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hfwvWU5gp54L"
   },
   "outputs": [],
   "source": [
    "df.rename(columns = {\n",
    "    'Sentence': 'text',\n",
    "    'Tag': 'tag'\n",
    "}, inplace = True)\n",
    "df['tag'] = df['tag'].str.replace('comapny', 'company')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-VA7akGZpDyo"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(['company', 'jobdescription', 'joblocation_address', 'jobtitle', 'skills'])\n",
    "df.tag = le.transform(df.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "52B85RkIpDyt",
    "outputId": "e49e3997-a9eb-4c7f-9a46-5da4eade929a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development engineer – time metrology</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whose mandate provide basis coherent system m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bipm base sèvres outskirts  staff 70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>laboratory equip characterization gnss time t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>principal duty responsibility reporting direct...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  tag\n",
       "0              development engineer – time metrology    4\n",
       "1   whose mandate provide basis coherent system m...    0\n",
       "2               bipm base sèvres outskirts  staff 70    0\n",
       "3   laboratory equip characterization gnss time t...    4\n",
       "4  principal duty responsibility reporting direct...    4"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vMuZfqPqpDyx"
   },
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAeJbRFzpDyy"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_df.csv', names = [\"text\"], skiprows=1)\n",
    "test.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMcw8N1ppDy1"
   },
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhzXQG7apDy2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.text, df.tag, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "entvgHhPpDy9"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_val = X_val.values\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "\n",
    "X_test = test['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_NlchSWpDzC"
   },
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yvjschrvpDzD",
    "outputId": "1d5bfa3a-051d-4c19-a5b5-78d42f5b69e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0HUrTCa0pDzL"
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t')\n",
    "    data['tags'] = data['tags'].apply(literal_eval)# drop the '' from inside tags\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOXZuDuppDzT"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ok6SCE-EpDzX"
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def text_prepare(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, \" \", text)\n",
    "    text = re.sub(BAD_SYMBOLS_RE, \"\", text)\n",
    "    text = \" \".join([word for word in re.split(\" \", text) if (not word in STOPWORDS and not word == \"\")])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HNQtbXS-pDzd"
   },
   "source": [
    "Now we preprocess the text using function *text_prepare*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXukbE5LpDzf"
   },
   "outputs": [],
   "source": [
    "X_train = [text_prepare(x) for x in X_train]\n",
    "X_val = [text_prepare(x) for x in X_val]\n",
    "\n",
    "X_test = [text_prepare(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "v8n74kMWpDzj",
    "outputId": "700e2c29-9b79-4b17-8aa4-9bfc3f40a105"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spirit community diversity people skill background experience make us strong',\n",
       " 'working large global organization youll chance grow professionally personally expand career',\n",
       " 'different']"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wh6MO1IspDzo"
   },
   "source": [
    "For each tag and for each word we calculate how many times they occur in the train corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "59CEfu6DpDzp",
    "outputId": "4cbf2dac-8639-476f-ee53-a3678b3009b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting words..\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of all words from train corpus with their counts.\n",
    "words_counts = {}\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print(\"counting words..\")\n",
    "words = []\n",
    "for title in X_train:\n",
    "    words = words + title.split()\n",
    "\n",
    "print(\"done\")\n",
    "words_counts = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_pt7FjXUsEg3",
    "outputId": "0a3cb74a-7fc4-47d9-bf67-f7a41806039d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5358"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJkYOEpjpDzs"
   },
   "source": [
    "#### Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wItj11YLpDzv"
   },
   "outputs": [],
   "source": [
    "DICT_SIZE = 5000\n",
    "WORDS_TO_INDEX = {word:i for i,word in enumerate([word for word,_ in sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:DICT_SIZE]])}\n",
    "INDEX_TO_WORDS = dict(enumerate(list(WORDS_TO_INDEX)))\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()\n",
    "\n",
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for word,i in words_to_index.items():\n",
    "        if word in text.split():\n",
    "            result_vector[i] = result_vector[i] + 1\n",
    "    \n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVh_UCPbpDz1"
   },
   "source": [
    "Now we apply the implemented function to all samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XFb3awiqpDz2"
   },
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kfl2WB1qpD0A",
    "outputId": "a716c60f-f493-4259-a57a-f67f66d1386e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (3790, 5000)\n",
      "X_val shape  (1264, 5000)\n",
      "X_test shape  (5054, 5000)\n"
     ]
    }
   ],
   "source": [
    "#X_train_mybag.toarray() to decompress the matrix\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])\n",
    "\n",
    "print('X_train shape ', X_train_mybag.shape)\n",
    "print('X_val shape ', X_val_mybag.shape)\n",
    "print('X_test shape ', X_test_mybag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "An9J6b0NpD0G"
   },
   "source": [
    "We transform the data to sparse representation, to store the useful information efficiently.\n",
    "\n",
    "Sklearn algorithms can work only with **csr** matrix, so we will use this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H3dDoXA4pD0H"
   },
   "source": [
    "#### TF-IDF\n",
    "\n",
    "The second approach extends the bag-of-words framework by taking into account total frequencies of words in the corpora. It helps to penalize too frequent words and provide better features space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDYChSTQpD0I"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aR0rHjBbpD0N"
   },
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.9, ngram_range=(1, 2), token_pattern= '(\\S+)')\n",
    "    \n",
    "    X_train=tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_val=tfidf_vectorizer.transform(X_val)\n",
    "    \n",
    "    X_test=tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train, X_val, X_test, tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mw9x7DFppD0U"
   },
   "source": [
    "Now we apply the implemented function to all samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "miNQ_9wJpD0V"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)\n",
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcwlkJDApD0Z"
   },
   "source": [
    "#### Shape Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8wYCxJF6pD0Z",
    "outputId": "8bedd775-3d47-4c7c-a784-aadba89802bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of X_train_mybag: (3790, 5000)\n",
      " Shape of X_train_tfidf: (3790, 1958)\n"
     ]
    }
   ],
   "source": [
    "print(\" Shape of X_train_mybag:\", X_train_mybag.shape)\n",
    "print(\" Shape of X_train_tfidf:\", X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "guI9ZwJxpD0e"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-GbO5_Q_pD0f"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLgMEsx0pD0k"
   },
   "outputs": [],
   "source": [
    "def train_classifier(X_train, y_train):\n",
    "\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6AY8Vg4pD0t"
   },
   "source": [
    "Training the classifiers for different data transformations: *bag-of-words* and *tf-idf*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRbkt86bpD0u"
   },
   "outputs": [],
   "source": [
    "classifier_mybag = train_classifier(X_train_mybag, y_train)\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDMUe_KipD0z"
   },
   "source": [
    "Now we create predictions for the data. We will need two types of predictions: labels and scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3PuULlXTpD01"
   },
   "outputs": [],
   "source": [
    "y_val_predicted_labels_mybag = classifier_mybag.predict(X_val_mybag)\n",
    "y_val_predicted_scores_mybag = classifier_mybag.decision_function(X_val_mybag)\n",
    "\n",
    "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnTHl3QKpD05"
   },
   "source": [
    "Now we can take a look at how classifier, which uses TF-IDF, works for a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "Aaimy1kGpD05",
    "outputId": "4b06be3d-7862-4f1a-e64c-eb92aa249762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\t40 country 5 continent\n",
      "True labels:\tcompany\n",
      "Predicted labels:\tskills\n",
      "\n",
      "\n",
      "Text:\tadhere agile project set direction data science initiative qualifications masters bachelors quantitative discipline eg\n",
      "True labels:\tskills\n",
      "Predicted labels:\tskills\n",
      "\n",
      "\n",
      "Text:\tparametrize exposure model\n",
      "True labels:\tskills\n",
      "Predicted labels:\tskills\n",
      "\n",
      "\n",
      "Text:\texcellent write verbal communication skill include report write technical document\n",
      "True labels:\tskills\n",
      "Predicted labels:\tskills\n",
      "\n",
      "\n",
      "Text:\tmathematics etc\n",
      "True labels:\tskills\n",
      "Predicted labels:\tskills\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Text:\\t{}\\nTrue labels:\\t{}\\nPredicted labels:\\t{}\\n\\n'.format(\n",
    "        X_val[i],\n",
    "        list(le.inverse_transform(y_val))[i],\n",
    "        list(le.inverse_transform(y_val_predicted_labels_mybag))[i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mk9seXY1pD0-"
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "To evaluate the results we will use several classification metrics:\n",
    " - Accuracy\n",
    " - F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "INQFgqKSpD0_"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-uupgxcpD1E"
   },
   "outputs": [],
   "source": [
    "def print_evaluation_scores(y_val, predicted):\n",
    "    \n",
    "    accuracy=accuracy_score(y_val, predicted)\n",
    "    f1_score_macro=f1_score(y_val, predicted, average='macro')\n",
    "    f1_score_micro=f1_score(y_val, predicted, average='micro')\n",
    "    f1_score_weighted=f1_score(y_val, predicted, average='weighted')\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1-score macro:\", f1_score_macro)\n",
    "    print(\"F1-score micro:\", f1_score_micro)\n",
    "    print(\"F1-score weighted:\", f1_score_weighted)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "iqBmFt3qpD1I",
    "outputId": "7ee9174d-8a98-4841-c247-d9f0fa524d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words\n",
      "Accuracy: 0.7468354430379747\n",
      "F1-score macro: 0.4713936370333386\n",
      "F1-score micro: 0.7468354430379747\n",
      "F1-score weighted: 0.7188770060462132\n",
      "\n",
      "Tfidf\n",
      "Accuracy: 0.7484177215189873\n",
      "F1-score macro: 0.35538080894431534\n",
      "F1-score micro: 0.7484177215189873\n",
      "F1-score weighted: 0.6965920924203463\n"
     ]
    }
   ],
   "source": [
    "print('Bag-of-words')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_mybag)\n",
    "print()\n",
    "print('Tfidf')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdKYHJUqpD1O"
   },
   "source": [
    "### Predictions for *test* set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Uo7aDWXJpD1O",
    "outputId": "8e0fa617-4829-48f0-c507-f8aef35d63ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction BagOfWords</th>\n",
       "      <th>prediction TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>project may deliver hardware system technical ...</td>\n",
       "      <td>skills</td>\n",
       "      <td>skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>key responsibility specific responsibility job...</td>\n",
       "      <td>skills</td>\n",
       "      <td>skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>help invent prototype technology</td>\n",
       "      <td>skills</td>\n",
       "      <td>skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>create haptic interface beyond</td>\n",
       "      <td>skills</td>\n",
       "      <td>skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>research contribute emerge technology standard...</td>\n",
       "      <td>skills</td>\n",
       "      <td>skills</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ... prediction TFIDF\n",
       "0  project may deliver hardware system technical ...  ...           skills\n",
       "1  key responsibility specific responsibility job...  ...           skills\n",
       "2                   help invent prototype technology  ...           skills\n",
       "3                     create haptic interface beyond  ...           skills\n",
       "4  research contribute emerge technology standard...  ...           skills\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predicted_labels_mybag = classifier_mybag.predict(X_test_mybag)\n",
    "y_test_predicted_labels_tfidf = classifier_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "result_part1 = pd.DataFrame()\n",
    "result_part1[\"text\"] = X_test\n",
    "result_part1[\"prediction BagOfWords\"] = le.inverse_transform(y_test_predicted_labels_mybag)\n",
    "result_part1[\"prediction TFIDF\"] = le.inverse_transform(y_test_predicted_labels_tfidf)\n",
    "\n",
    "result_part1.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ProjetML-Partie1-MonoLabel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
